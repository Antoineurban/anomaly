@InProceedings{blinding,
author="Shin, Hocheol
and Kim, Dohyun
and Kwon, Yujin
and Kim, Yongdae",
editor="Fischer, Wieland
and Homma, Naofumi",
title="Illusion and Dazzle: Adversarial Optical Channel Exploits Against Lidars for Automotive Applications",
booktitle="Cryptographic Hardware and Embedded Systems -- CHES 2017",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="445--467",
abstract="With the advancement in computing, sensing, and vehicle electronics, autonomous vehicles are being realized. For autonomous driving, environment perception sensors such as radars, lidars, and vision sensors play core roles as the eyes of a vehicle; therefore, their reliability cannot be compromised. In this work, we present a spoofing by relaying attack, which can not only induce illusions in the lidar output but can also cause the illusions to appear closer than the location of a spoofing device. In a recent work, the former attack is shown to be effective, but the latter one was never shown. Additionally, we present a novel saturation attack against lidars, which can completely incapacitate a lidar from sensing a certain direction. The effectiveness of both the approaches is experimentally verified against Velodyne's VLP-16.",
isbn="978-3-319-66787-4"
}

@InProceedings{ref1, 
author={N. Deepika and V. V. Sajith Variyar}, 
booktitle={2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI)}, 
title={Obstacle classification and detection for vision based navigation for autonomous driving}, 
year={2017}, 
volume={}, 
number={}, 
pages={2092-2097}, 
abstract={With the rising trend in research and development of autonomous vehicles, it is important to keep in mind the cost effectiveness of the system. The cost of high-end sensor technologies being astronomically expensive, the research opportunities are restricted to a select few of high-tech companies and research laboratories such as Google, Tesla, Ford, and the likes of it. Hence our main focus is to develop an autonomous system suitable for academic and research purposes as well. This can be achieved by using available sensors such as the monocular cameras. The existing computer vision techniques along with the deep learning tools like Convolutional Neural Network (CNN) can together be used for developing a robust vision based autonomous driving system. The proposed method uses the SegNet encoder-decoder architecture for pixel-wise semantic segmentation of the video frame followed by an obstacle detection algorithm. The entire algorithm was implemented and tested on a mobile embedded platform of NVIDIA's Jetson TK1.}, 
keywords={computer vision;driver information systems;image classification;image segmentation;learning (artificial intelligence);neural nets;object detection;video signal processing;Convolutional Neural Network;SegNet encoder-decoder architecture;autonomous system;autonomous vehicles;computer vision techniques;deep learning tools;high-end sensor technologies;mobile embedded platform;monocular cameras;obstacle classification;obstacle detection algorithm;pixel-wise semantic segmentation;robust vision based autonomous driving system;video frame;vision based navigation;Autonomous vehicles;Cameras;Computer architecture;Image segmentation;Roads;Robot sensing systems;Semantics}, 
doi={10.1109/ICACCI.2017.8126154}, 
ISSN={}, 
month={Sept},}

@article{ref2,
title = "Obstacle Detection with Ultrasonic Sensors and Signal Analysis Metrics",
journal = "Transportation Research Procedia",
volume = "28",
pages = "173 - 182",
year = "2017",
note = "INAIR 2017",
issn = "2352-1465",
doi = "https://doi.org/10.1016/j.trpro.2017.12.183",
url = "http://www.sciencedirect.com/science/article/pii/S2352146517311031",
author = "Gerard Gibbs and Huamin Jia and Irfan Madani",
keywords = "Kalman filter, Lomb Algorithm, Cross correlation, Envelope detector, Energy power density",
abstract = "One of the basic tasks for autonomous flight with aerial vehicles (drones) is the detection of obstacles within its flight environment. As the technology develops and becomes more robust, drones will become part of the toolkit to aid maintenance repair and operation (MRO) and ground personnel at airports. Currently laser technology is the primary means for obstacle detection as it provides high resolution and long range. The high intensity laser beam can result in temporary blindness for pilots when the beam targets the windscreen of aircraft on the ground or on final approach within the vicinity of the airport. An alternative is ultrasonic sensor technology, but this suffers from poor angular resolution. In this paper we present a solution using time-of-flight (TOF) data from ultrasonic sensors. This system uses a single commercial 40 kHz combined transmitter/ receiver which returns the distance to the nearest obstacle in its field of view, +/- 30 degrees given the speed of sound in air at ambient temperature. Two sonar receivers located either side of the transmitter / receiver are mounted on a horizontal rotating shaft. Rotation of this shaft allows for separate sonar observations at regular intervals which cover the field of view of the transmitter / receiver. To reduce the sampling frequency an envelope detector is used prior to the analogue-digital-conversion for each of the sonar channels. A scalar Kalman filter for each channel reduces the effects of signal noise by providing real time filtering (Drongelen, 2017a). Four signal metrics are used to determine the location of the obstacle in the sensors field of view: 1. Maximum (Peak) frequency2. Cross correlation of raw data and PSD3. Power Spectral Density4. Energy Spectral Density Results obtained in an actual indoor environment are presented to support the validity of the proposed algorithm."
}

@ARTICLE{Vapnik, 
author={V. N. Vapnik}, 
journal={IEEE Transactions on Neural Networks}, 
title={An overview of statistical learning theory}, 
year={1999}, 
volume={10}, 
number={5}, 
pages={988-999}, 
abstract={Statistical learning theory was introduced in the late 1960's. Until the 1990's it was a purely theoretical analysis of the problem of function estimation from a given collection of data. In the middle of the 1990's new types of learning algorithms (called support vector machines) based on the developed theory were proposed. This made statistical learning theory not only a tool for the theoretical analysis but also a tool for creating practical algorithms for estimating multidimensional functions. This article presents a very general overview of statistical learning theory including both theoretical and algorithmic aspects of the theory. The goal of this overview is to demonstrate how the abstract learning theory established conditions for generalization which are more general than those discussed in classical statistical paradigms and how the understanding of these conditions inspired new algorithmic approaches to function estimation problems}, 
keywords={estimation theory;generalisation (artificial intelligence);learning (artificial intelligence);statistical analysis;function estimation;generalization conditions;multidimensional function estimation;statistical learning theory;support vector machines;Algorithm design and analysis;Loss measurement;Machine learning;Multidimensional systems;Pattern recognition;Probability distribution;Risk management;Statistical learning;Support vector machines}, 
doi={10.1109/72.788640}, 
ISSN={1045-9227}, 
month={Sep},}

@article{Crammer,
  title={On the algorithmic implementation of multiclass kernel-based vector machines},
  author={Crammer, Koby and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={2},
  number={Dec},
  pages={265--292},
  year={2001}
}

@Article{work1,
author="Bendjaballah, Mourad
and Graovac, Stevica
and Boulahlib, Mohammed Amine",
title="A classification of on-road obstacles according to their relative velocities",
journal="EURASIP Journal on Image and Video Processing",
year="2016",
month="Dec",
day="05",
volume="2016",
number="1",
pages="41",
abstract="The systems based on image processing have numerous applications in the domain of motion control of robots and autonomous vehicles. The current paper is oriented to the solution of the problem that precedes the implementation of automatic avoidance of the on-road obstacles---how to detect them, to track in the sequence of images, and to recognize which of them are stationary, incoming, or outgoing from the camera. The overall algorithm of obstacle classification presented in this paper consists of three basic phases: (1) image segmentation in order to extract the pixels belonging to the image of a road and the objects over it; (2) extraction of characteristic points inside the area of the obstacle, their description and tracking in following frames; and (3) estimation of distances between the camera, the obstacles and their rates of change (relative velocities). The verifications of particular steps of the proposed algorithm are illustrated using real road-traffic images, while the overall algorithm is tested using both synthesized sequences of images and the ones acquired in real driving.",
issn="1687-5281",
doi="10.1186/s13640-016-0147-0",
url="https://doi.org/10.1186/s13640-016-0147-0"
}

@INPROCEEDINGS{work2, 
author={D. V. Prokhorov}, 
booktitle={2010 IEEE Intelligent Vehicles Symposium}, 
title={Road obstacle classification with attention windows}, 
year={2010}, 
volume={}, 
number={}, 
pages={889-895}, 
abstract={A learning system for detection and classification of road obstacles, such as vehicles and non-vehicles, is proposed which utilizes information from multiple sensors. An advanced range sensor guides a selection of candidate images provided by the camera for subsequent analysis. A competition based learning algorithm is used to distinguish between representations of different obstacles. High classification accuracy is demonstrated in a realistic variety of driving conditions in the presence of intentional data mislabeling in the two-class setup with state-of-art image descriptors.}, 
keywords={driver information systems;image classification;image sensors;learning (artificial intelligence);object detection;attention windows;competition based learning algorithm;driver support;image descriptors;intentional data mislabeling;learning system;multiple sensors;road obstacle classification;road obstacle detection;Cameras;Image analysis;Intelligent sensors;Laser radar;Object detection;Radar detection;Radar imaging;Road vehicles;Sensor systems;Vehicle detection}, 
doi={10.1109/IVS.2010.5548053}, 
ISSN={1931-0587}, 
month={June},}

@ARTICLE{work3, 
author={M. S. Darms and P. E. Rybski and C. Baker and C. Urmson}, 
journal={IEEE Transactions on Intelligent Transportation Systems}, 
title={Obstacle Detection and Tracking for the Urban Challenge}, 
year={2009}, 
volume={10}, 
number={3}, 
pages={475-485}, 
abstract={This paper describes the obstacle detection and tracking algorithms developed for Boss, which is Carnegie Mellon University 's winning entry in the 2007 DARPA Urban Challenge. We describe the tracking subsystem and show how it functions in the context of the larger perception system. The tracking subsystem gives the robot the ability to understand complex scenarios of urban driving to safely operate in the proximity of other vehicles. The tracking system fuses sensor data from more than a dozen sensors with additional information about the environment to generate a coherent situational model. A novel multiple-model approach is used to track the objects based on the quality of the sensor data. Finally, the architecture of the tracking subsystem explicitly abstracts each of the levels of processing. The subsystem can easily be extended by adding new sensors and validation algorithms.}, 
keywords={mobile robots;object detection;road vehicles;sensor fusion;target tracking;2007 DARPA Urban Challenge;Boss;Carnegie Mellon University;autonomous vehicle;multiple-model approach;obstacle detection;obstacle tracking;perceptual system;robot;sensor data;tracking subsystem;urban driving;Object tracking;Tartan Racing;obstacle classification;obstacle detection;situational reasoning;system architecture}, 
doi={10.1109/TITS.2009.2018319}, 
ISSN={1524-9050}, 
month={Sept},}

@ARTICLE{work4, 
author={M. Liang and X. Huang and C. H. Chen and X. Chen and A. Tokuta}, 
journal={IEEE Transactions on Intelligent Transportation Systems}, 
title={Counting and Classification of Highway Vehicles by Regression Analysis}, 
year={2015}, 
volume={16}, 
number={5}, 
pages={2878-2888}, 
abstract={In this paper, we describe a novel algorithm that counts and classifies highway vehicles based on regression analysis. This algorithm requires no explicit segmentation or tracking of individual vehicles, which is usually an important part of many existing algorithms. Therefore, this algorithm is particularly useful when there are severe occlusions or vehicle resolution is low, in which extracted features are highly unreliable. There are mainly two contributions in our proposed algorithm. First, a warping method is developed to detect the foreground segments that contain unclassified vehicles. The common used modeling and tracking (e.g., Kalman filtering) of individual vehicles are not required. In order to reduce vehicle distortion caused by the foreshortening effect, a nonuniform mesh grid and a projective transformation are estimated and applied during the warping process. Second, we extract a set of low-level features for each foreground segment and develop a cascaded regression approach to count and classify vehicles directly, which has not been used in the area of intelligent transportation systems. Three different regressors are designed and evaluated. Experiments show that our regression-based algorithm is accurate and robust for poor quality videos, from which many existing algorithms could fail to extract reliable features.}, 
keywords={image classification;image resolution;intelligent transportation systems;regression analysis;road vehicles;video signal processing;cascaded regression approach;extracted features;foreground segments;foreshortening effect;highway vehicle classification;intelligent transportation systems;low-level features;nonuniform mesh grid;occlusions;poor quality videos;projective transformation;regression analysis;regression-based algorithm;unclassified vehicles;vehicle distortion;vehicle resolution;Algorithm design and analysis;Feature extraction;Image segmentation;Roads;Vehicles;Videos;Highway vehicle;cascaded regression;image warping}, 
doi={10.1109/TITS.2015.2424917}, 
ISSN={1524-9050}, 
month={Oct},}

@misc{carquery,
  title = {CarQuery, The Vehicle Data API \& Database},
  howpublished = {Disponible sur \url{http://www.carqueryapi.com}},
  note = {Consulté le 2018-06-20}
}

@misc{pandas,
  title = {Pandas, Python Data Analysis Library},
  howpublished = {Disponible sur \url{http://pandas.pydata.org}},
  note = {Consulté le 2018-06-20}
}

@misc{venv,
  title = {Virtualenv},
  howpublished = {Disponible sur \url{https://virtualenv.pypa.io/en/stable/}},
  note = {Consulté le 2018-06-20}
}

@misc{numpy,
  title = {Numpy},
  howpublished = {Disponible sur \url{http://www.numpy.org}},
  note = {Consulté le 2018-06-20}
}

@misc{matplotlib,
  title = {Matplotlib: Python plotting},
  howpublished = {Disponible sur \url{https://matplotlib.org}},
  note = {Consulté le 2018-06-20}
}

@misc{jupyter,
  title = {Project Jupyter},
  howpublished = {Disponible sur \url{http://jupyter.org}},
  note = {Consulté le 2018-06-20}
}

@misc{sklearn,
  title = {scikit-learn: machine learning in Python},
  howpublished = {Disponible sur \url{http://scikit-learn.org/stable/index.html}},
  note = {Consulté le 2018-06-20}
}

@misc{git,
  title = {anomaly},
  howpublished = {Disponible sur \url{https://github.com/ychalier/anomaly/}},
  note = {Consulté le 2018-06-20}
}
